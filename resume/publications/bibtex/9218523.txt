@INPROCEEDINGS{9218523,

  author={C. {Chu} and Y. {Wang} and Y. {Zhao} and X. {Ma} and S. {Ye} and Y. {Hong} and X. {Liang} and Y. {Han} and L. {Jiang}},

  booktitle={2020 57th ACM/IEEE Design Automation Conference (DAC)}, 

  title={PIM-Prune: Fine-Grain DCNN Pruning for Crossbar-Based Process-In-Memory Architecture}, 

  year={2020},

  volume={},

  number={},

  pages={1-6},

  abstract={Deep Convolution Neural network (DCNN) pruning is an efficient way to reduce the resource and power consumption in a DCNN accelerator. Exploiting the sparsity in the weight matrices of DCNNs, however, is nontrivial if we deploy these DC-NNs in a crossbar-based Process-In-Memory (PIM) architecture, because of the crossbar structure. Structural pruning-exploiting a coarse-grained sparsity, such as filter/channel-level pruning-can result in a compressed weight matrix that fits the crossbar structure. However, this pruning method inevitably degrades the model accuracy. To solve this problem, in this paper, we propose PIM-PRUNE to exploit the finer-grained sparsity in PIM-architecture, and the resulting compressed weight matrices can significantly reduce the demand of crossbars with negligible accuracy loss. Further, we explore the design space of the crossbar, such as the crossbar size and aspect-ratio, from a new point-of-view of resource-oriented pruning. We find a trade-off existing between the pruning algorithm and the hardware overhead: a PIM with smaller crossbars is more friendly for pruning methods; however, the resulting peripheral circuit cause higher power consumption. Given a specific DCNN, we can suggest a sweet-spot of crossbar design to the optimal overall energy efficiency. Experimental results show that the proposed pruning method applied on Resnet18 can achieve up to 24.85× and 3.56× higher compression rate of occupied crossbars on CifarlO and Imagenet, respectively; while the accuracy loss is negligible, which is 4.56× and 1.99× better than the state-of-art methods.},

  keywords={convolutional neural nets;data compression;memory architecture;power aware computing;pruning method;finer-grained sparsity;PIM-architecture;compressed weight matrices;negligible accuracy loss;crossbar size;resource-oriented pruning;pruning algorithm;smaller crossbars;specific DCNN;crossbar design;occupied crossbars;PIM-Prune;fine-grain DCNN Pruning;crossbar-based process-in-memory architecture;DCNN accelerator;crossbar structure;structural pruning-exploiting;coarse-grained sparsity;compressed weight matrix;resulting peripheral circuit;higher power consumption;deep convolution neural network pruning;Computer architecture;Space exploration;Hardware;Convolution;Neural networks;Memristors;Two dimensional displays;Crossbar;DCNN pruning;PIM},

  doi={10.1109/DAC18072.2020.9218523},

  ISSN={0738-100X},

  month={July},}
