<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Y.L. Zhao</title>
    <description>My site is built on Nov. 24, 2019. It is used to record something I am interested in.
</description>
    <link>https://xiaoke0515.github.io//</link>
    <atom:link href="https://xiaoke0515.github.io//feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 06 Jul 2020 18:09:41 +0800</pubDate>
    <lastBuildDate>Mon, 06 Jul 2020 18:09:41 +0800</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>VMWare 提示与 Hyper-V冲突；如何在Windows 上彻底关闭Hyper-V</title>
        <description>&lt;p&gt;前几天看到Windows功能中的虚拟机功能，突然好奇，手贱给打开了，觉得没什么意思，就也没动。直到今天打开VMWare提示与Hyper-V冲突。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;您的主机不满足在启用 Hyper-V 或 Device/Credential Guard 的情况下运行 VMware。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;打开 VMWare 官方文档就是让关闭 Hyper-V。但是其实在我的个人版 Windows 是没有 Hyper-V 选项的。在搜了半天 Hyper-V 是啥才想到可能是和我前几天打开的那个虚拟机功能有关。&lt;/p&gt;

&lt;p&gt;在我关闭这个功能之后，事情并没有改善，我一度以为思路错了，直到我继续谷歌半天才确定就是这个辣鸡虚拟机功能搞的鬼。***&lt;/p&gt;

&lt;h2 id=&quot;解决问题记录&quot;&gt;解决问题记录&lt;/h2&gt;

&lt;p&gt;原因还是 Hyper-V 和 VMWare 不兼容。所以这里实际记录的实际上是如何彻底关闭 Hyper-V。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;小娜-&amp;gt;启用和关闭Windows功能-&amp;gt;关闭 虚拟机平台（或Hyper-V）&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/others/1_figure_windows_function.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;小娜-&amp;gt;计算机管理-&amp;gt;服务和应用程序-&amp;gt;服务-&amp;gt;把所有带 Hyper-V 的停止并禁用。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/others/1_figure_windows_service.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重启计算机&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;问题解决。&lt;/p&gt;
</description>
        <pubDate>Mon, 06 Jul 2020 00:00:00 +0800</pubDate>
        <link>https://xiaoke0515.github.io//others/2020/07/06/1_Close_Hyper-V.html</link>
        <guid isPermaLink="true">https://xiaoke0515.github.io//others/2020/07/06/1_Close_Hyper-V.html</guid>
        
        <category>record</category>
        
        
        <category>others</category>
        
      </item>
    
      <item>
        <title>FMNN 论文：A Switched Operation Approach to Sampled-Data Control Stabilization of Fuzzy Memristive Neural Networks With Time-Varying Delay</title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;authors:
Xin Wang , Ju H. Park , Shouming Zhong , and Huilan Yang of Southwest University, Chongqing 400715, China&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;X. Wang, J. H. Park, S. Zhong and H. Yang, “A Switched Operation Approach to Sampled-Data Control Stabilization of Fuzzy Memristive Neural Networks With Time-Varying Delay,” in IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 3, pp. 891-900, March 2020, doi: 10.1109/TNNLS.2019.2910574.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here is abstract:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This paper investigates the issue of sampled-data stabilization for Takagi-Sugeno fuzzy memristive neural networks (FMNNs) with time-varying delay. First, the concerned FMNNs are transformed into the tractable fuzzy NNs based on the excitatory and inhibitory of memristive synaptic weights using a new convex combination technique. Meanwhile, a switched fuzzy sampled-data controller is employed for the first time to tackle stability problems related to FMNNs. Then, the novel stabilization criteria of the FMNNs are established using the fuzzy membership functions (FMFs)-dependent Lyapunov-Krasovskii functional. This sufficiently utilizes information from not only the delayed state and the actual sampling pattern but also the FMFs. Two simulation examples are presented to demonstrate the feasibility and validity of the proposed method.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;background--takagisugeno-ts-fuzzy-model&quot;&gt;Background : Takagi–Sugeno (T–S) fuzzy model&lt;/h2&gt;

&lt;p&gt;Refering: &lt;a href=&quot;https://wenku.baidu.com/view/5c66a4a5ad51f01dc281f178.html&quot;&gt;T-S模糊模型&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;contribution&quot;&gt;Contribution:&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;FMNNs were transformed into the tractable fuzzy NNs using a new convex combination
technique by taking the excitatory and inhibitory of memristive synaptic weights into account.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A switched FSDC (SFSDC) was designed for the first time to solve the stabilization problem of FMNNs.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A switched FSDC (SFSDC) was designed for the first time to solve the stabilization problem of FMNNs.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;network-model&quot;&gt;Network Model:&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;(to be continued)&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 02 Jul 2020 00:00:00 +0800</pubDate>
        <link>https://xiaoke0515.github.io//mnn_paper/2020/07/02/1_FMNN.html</link>
        <guid isPermaLink="true">https://xiaoke0515.github.io//mnn_paper/2020/07/02/1_FMNN.html</guid>
        
        <category>analog computing</category>
        
        <category>MNN</category>
        
        
        <category>MNN_paper</category>
        
      </item>
    
      <item>
        <title>Time signal 论文：Analysis and Design of Energy Efficient Time Domain Signal Processing</title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;blockquote&gt;
  &lt;p&gt;Zhengyu Chen, Jie Gu, Analysis and Design of Energy Efficient Time Domain Signal Processing, International Symposium on Low Power Electronic Design (ISLPED), 2016.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The paper is &lt;a href=&quot;&amp;quot;dl.acm.org/citation.cfm?id=2934585&amp;quot;&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My first time ever heard about using time signal for ReRAM accelerator. Found this paper to learn some details.&lt;/p&gt;

&lt;p&gt;Let’s see abstract first：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Time domain signal processing (TDSP) encodes information into time rather than voltage with higher efficiency than conventional digital design. This paper performs systematical analysis on the design principle and energy efficiency of TDSP. Variation impact, which poses significant challenges to TDSP, is evaluated and a variation driven design methodology is proposed to achieve an optimum tradeoff between energy efficiency and design robustness. Several novel circuit level design techniques such as dual encoding strategy and bit-scalable design are also proposed in this work to significantly improve the energy efficiency of TDSP. Design example on a critical building block of facial recognition application was used to demonstrate the potential of the technique. The result in a 45nm technology shows 3.3X energy-delay product reduction and 34% area saving can be achieved using TDSP compared with conventional digital.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;1-time-signal-processing&quot;&gt;1. Time signal processing&lt;/h2&gt;

&lt;h3 id=&quot;11-system&quot;&gt;1.1 system&lt;/h3&gt;

&lt;p&gt;System is described in figure below. It’s composed of en/decoders and time domain logic.&lt;/p&gt;

&lt;!--![System overview](/img/ReRAM_DNN_accelerator/1_figure_system.jpg)--&gt;
&lt;p&gt;&lt;img src=&quot;/img/ReRAM_DNN_accelerator/1_figure_system.jpg&quot; alt=&quot;System overview&quot; width=&quot;300&quot; align=&quot;bottom&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;12-time-encoder&quot;&gt;1.2 Time Encoder&lt;/h3&gt;

&lt;p&gt;Time encoder is also called DTC (Digital-to-Time Converter). Figure below shows some impementation of DTCs.&lt;/p&gt;

&lt;!--![TE](/img/ReRAM_DNN_accelerator/1_figure_te.jpg)--&gt;
&lt;p&gt;&lt;img src=&quot;/img/ReRAM_DNN_accelerator/1_figure_te.jpg&quot; alt=&quot;TE&quot; width=&quot;300&quot; align=&quot;bottom&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Tech. (a) is proposed in &lt;a href=&quot;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=6630119&quot;&gt;This Paper&lt;/a&gt;. &lt;script type=&quot;math/tex&quot;&gt;T_{in}&lt;/script&gt; is the time signal, such as &lt;em&gt;Step Signal&lt;/em&gt;. &lt;script type=&quot;math/tex&quot;&gt;D_{in}&lt;/script&gt; is the digital signal. By selecting different path with &lt;script type=&quot;math/tex&quot;&gt;D_{in}&lt;/script&gt;, delay of signal &lt;script type=&quot;math/tex&quot;&gt;T_{out}&lt;/script&gt; is decided. The design suffer from energy problem because of (1) multiple gates (2) signal returning to original stage which cause &lt;script type=&quot;math/tex&quot;&gt;2\times&lt;/script&gt; energy consumption.&lt;/p&gt;

&lt;p&gt;Tech. (b) can encode multi-bit with a single inverter. (1) &lt;script type=&quot;math/tex&quot;&gt;3\times&lt;/script&gt; energy saving compared to (a). (2) energy consumption is a constant even if embedding multi-bit.&lt;/p&gt;

&lt;p&gt;Tech. (c)(d) are “Cascade TE”. To be further discuess in the next sections.&lt;/p&gt;

&lt;h3 id=&quot;13-dual-encoding-scheme&quot;&gt;1.3 Dual-encoding Scheme&lt;/h3&gt;

&lt;p&gt;Compared to Tech. (a), which only encode information to only one kind of edge (raising or falling), this scheme means that encode information into both the two edges for energy saving. For more details, please refer to the paper.&lt;/p&gt;

&lt;h3 id=&quot;14-time-logic-cell-tlc&quot;&gt;1.4 Time Logic Cell (TLC)&lt;/h3&gt;

&lt;p&gt;No more words, see the figure below.&lt;/p&gt;

&lt;!--![TLC](/img/ReRAM_DNN_accelerator/1_figure_TLC.jpg)--&gt;
&lt;p&gt;&lt;img src=&quot;/img/ReRAM_DNN_accelerator/1_figure_TLC.jpg&quot; alt=&quot;TLC&quot; width=&quot;300&quot; align=&quot;bottom&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;15-time-decoder&quot;&gt;1.5 Time Decoder&lt;/h3&gt;

&lt;p&gt;A technology is described in figure blew. It is explicit and no more words.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ReRAM_DNN_accelerator/1_figure_TDC.jpg&quot; alt=&quot;TDC&quot; width=&quot;300&quot; align=&quot;bottom&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-variation-driven-design-methodology&quot;&gt;2. Variation-Driven Design Methodology&lt;/h2&gt;

&lt;h3 id=&quot;21-variation-driven-design&quot;&gt;2.1 Variation driven design&lt;/h3&gt;

&lt;p&gt;The auther introduces a energy-variation trade-off here. Consider the two kind of Tech. (c) (named cascade) and (d) (named cascode). As shown in figure below, cascade-type DTC has a larger energy but a smaller variation. Cascode-type DTC has an opposite characteristic. In order to trade off between energy and variation, a hybrid DTC is used.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ReRAM_DNN_accelerator/1_figure_tradeoff.jpg&quot; alt=&quot;trade off&quot; width=&quot;500&quot; align=&quot;bottom&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Details of energy consumption and variation is described with the following equations:&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\Delta T_{cascade\_TE}=\sqrt{2N}\sigma_1&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\Delta T_{cascode\_TE}=\sqrt{\sum_{i=1}^{n}\left(A+N_i\sigma_2\right)^2}&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\Delta T_{hybrid\_TE}=\sqrt{\sum_{i=1}^m\left(A+N_i\sigma_2\right)^2+\sum_{j=1}^{n-m}2^j\left(A+2^{m-1}\sigma_2\right)^2}&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;E_{cascade\_TE}=2N\cdot CV_{dd}^2&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;E_{cascode\_TE}=2nCV_{dd}^2&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;E_{hybrid\_TE}=\left(m+2^{n-m}\right)*2CV^2=\left(2m+2^{n-m+1}\right)CV^2&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;22-simulated-variation-impact&quot;&gt;2.2 Simulated Variation Impact&lt;/h3&gt;

&lt;p&gt;Simulated variation compared to conventional adder is shown in the figure below. It is amazing that time signal computing can achieve a such low variation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ReRAM_DNN_accelerator/1_figure_variation_result.jpg&quot; alt=&quot;variation_res&quot; width=&quot;300&quot; align=&quot;bottom&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-case-study&quot;&gt;3. Case Study&lt;/h2&gt;

&lt;p&gt;The following cases are studed in the origin paper:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Big-scalable design&lt;/li&gt;
  &lt;li&gt;Efficient MAX/MIN/CMP operation&lt;/li&gt;
  &lt;li&gt;Parallel operation with short cirtical path&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more details, please refer to the origin paper.&lt;/p&gt;

&lt;h2 id=&quot;4-conclusion&quot;&gt;4. Conclusion&lt;/h2&gt;

&lt;p&gt;Energy and area result is summrized in the following table:&lt;/p&gt;

&lt;!--| | CPU | Conventional ASIC | TDSP |
|:---:|:---:|:---:|:---:|
|Technology||||--&gt;

&lt;table align=&quot;center&quot; border=&quot;1&quot; frame=&quot;box&quot;&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;&amp;nbsp;&lt;/td&gt; 
        &lt;th&gt;CPU&lt;/th&gt; 
        &lt;th&gt;Conventional ASIC&lt;/th&gt; 
        &lt;th&gt;TDSP&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;th&gt; Technology &lt;/th&gt;
        &lt;td colspan=&quot;3&quot;&gt; 45nm, 1.1V &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;th&gt; Energy (fJ)&lt;/th&gt;
        &lt;td&gt; 2304 &lt;/td&gt;
        &lt;td&gt; 323 &lt;/td&gt;
        &lt;td&gt; 224.4 &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;th&gt; Area (&lt;span&gt;&lt;script type=&quot;math/tex&quot;&gt;\mu m^2&lt;/script&gt;&lt;/span&gt;)&lt;/th&gt;
        &lt;td&gt; N/A &lt;/td&gt;
        &lt;td&gt; 115 &lt;/td&gt;
        &lt;td&gt; 75.6 &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;th&gt; Delay (ns)&lt;/th&gt;
        &lt;td&gt; 3.2 &lt;/td&gt;
        &lt;td&gt; 0.98 &lt;/td&gt;
        &lt;td&gt; 0.43 &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;thoughts&quot;&gt;Thoughts&lt;/h2&gt;

&lt;p&gt;First ReRAM-based DNN accelerator that uses time signal is &lt;a href=&quot;&quot;&gt;Timely architecture&lt;/a&gt;. The author claims that TDC is much more energy efficient than ADC. This paper solve my confusion on how DTC and TDC works.&lt;/p&gt;

&lt;p&gt;Actually, I think DAC and TDC can also be a conversion pair. With a capacitance used as integrator, along with a comparator, analog signal can be converted to time signal.&lt;/p&gt;

&lt;p&gt;Moreover, the design in timely uses a circuit to store time signal, which is also what I am confused about.&lt;/p&gt;
</description>
        <pubDate>Sat, 06 Jun 2020 00:00:00 +0800</pubDate>
        <link>https://xiaoke0515.github.io//reram_paper/2020/06/06/1_Time_signal.html</link>
        <guid isPermaLink="true">https://xiaoke0515.github.io//reram_paper/2020/06/06/1_Time_signal.html</guid>
        
        <category>analog computing</category>
        
        <category>analog signal processing</category>
        
        
        <category>ReRAM_paper</category>
        
      </item>
    
      <item>
        <title>如何在建好TF图后修改图</title>
        <description>&lt;h1 id=&quot;如何在建好tf图后修改图&quot;&gt;如何在建好TF图后修改图&lt;/h1&gt;

&lt;p&gt;网上大部分教程都说tensorflow的图建好后是不能修改的，但是实际上是可以的。&lt;/p&gt;

&lt;h2 id=&quot;operation_update_input函数&quot;&gt;Operation._update_input()函数&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_update_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此函数的作用是将op的第i个输入变成new_tensor。&lt;/p&gt;

&lt;p&gt;下面的例子是用该函数将mul op的输入从b变成c。&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;SaveGraph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;makedirs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;writer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FileWriter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;writer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
    
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;a&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;b&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;c&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#build graph  &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# save graph&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SaveGraph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;tensorboard/before/&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# reroute operation mul&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;op&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;consumers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#&amp;lt;op here is the mul operation of d&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_update_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#&amp;lt;update the first input of op with c&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# save new graph&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SaveGraph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;tensorboard/after/&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在图建好后，tensorboard中的图如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Tensorflow/1/1_figure_before.jpg&quot; alt=&quot;reroute之前&quot; /&gt;
&lt;!-- (https://github.com/xiaoke0515/xiaoke0515.github.io/blob/master/content/Tensorflow/1-figure_before.jpg)--&gt;&lt;/p&gt;

&lt;p&gt;在修改图时，首先用consumers函数求b节点的所有下一级节点，即mul节点。随后用op._update_input()函数来将mul的第1个输入从b节点变成c节点。修改后图如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/Tensorflow/1/1_figure_after.jpg&quot; alt=&quot;reroute之后&quot; /&gt;
&lt;!-- (https://github.com/xiaoke0515/xiaoke0515.github.io/blob/master/content/Tensorflow/1-figure_after.jpg)--&gt;&lt;/p&gt;

&lt;p&gt;这样，mul的输入从b节点变成了c节点。&lt;/p&gt;

&lt;h2 id=&quot;在某个节点后插入op&quot;&gt;在某个节点后插入op&lt;/h2&gt;

&lt;p&gt;这个是在看tensorflow.contrib.quantize模块的create_training_graph函数代码后学会的。实现了个简单的InsertOP函数来完成这个功能。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;InsertOP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude_consumers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;consumers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_tensor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;consumers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude_consumers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_update_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;参数：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;in_tensor：在此tensor后插入op。&lt;/li&gt;
  &lt;li&gt;out_tensor：插入的op的输出的tensor。&lt;/li&gt;
  &lt;li&gt;exclude_consumers：是一个op的列表，表示in_tensor的所有consumer中，不希望插入out_tensor的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;用法：&lt;/p&gt;

&lt;p&gt;首先，定义一个要插入的op：&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NewOP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;exclude_consumers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude_consumers&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;它输出两个变量：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;out_tensor：NewOP输出的tensor。&lt;/li&gt;
  &lt;li&gt;exclude_consumers：插入的NewOP给in_tensor带来的新的consumers，这是一个值得注意的地方。
如果NewOP是一个节点，则exclude_consumers=[NewOP]；
如果NewOP是一个子图，那么exclude_consumers则是NewOP子图中所有的in_tensor的consumer。
如果不把这些consumer排除，那么在InsertOP后计算图会形成环。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;之后再用InsertOP函数插入NewOP。&lt;/p&gt;
</description>
        <pubDate>Wed, 03 Jun 2020 12:25:00 +0800</pubDate>
        <link>https://xiaoke0515.github.io//tensorflow/2020/06/03/1_Reroute_Tensor.html</link>
        <guid isPermaLink="true">https://xiaoke0515.github.io//tensorflow/2020/06/03/1_Reroute_Tensor.html</guid>
        
        <category>tensorflow</category>
        
        
        <category>tensorflow</category>
        
      </item>
    
      <item>
        <title>Welcome to Jekyll!</title>
        <description>&lt;p&gt;You’ll find this post in your &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;To add new posts, simply add a file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory that follows the convention &lt;code class=&quot;highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.ext&lt;/code&gt; and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Tom&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints &#39;Hi, Tom&#39; to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;http://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Tue, 02 Jun 2020 23:17:39 +0800</pubDate>
        <link>https://xiaoke0515.github.io//jekyll/update/2020/06/02/welcome-to-jekyll.html</link>
        <guid isPermaLink="true">https://xiaoke0515.github.io//jekyll/update/2020/06/02/welcome-to-jekyll.html</guid>
        
        <category>test</category>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
  </channel>
</rss>
